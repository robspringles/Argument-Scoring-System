{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic score prediction model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'comments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original number of data: \n",
      "2868\n"
     ]
    }
   ],
   "source": [
    "print (\"The original number of data: \")\n",
    "print (len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove none value \n",
    "new_data = data[np.isfinite(data['mean_evaluation'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing the nan evaluation value, the number of data: \n",
      "2562\n"
     ]
    }
   ],
   "source": [
    "print (\"After removing the nan evaluation value, the number of data: \")\n",
    "print (len(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nan evualuation items:\n",
      "306\n"
     ]
    }
   ],
   "source": [
    "print (\"The number of nan evualuation items:\")\n",
    "print (len(data) - len(new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_texts = new_data['comment_text']\n",
    "X = new_data['comment_text']\n",
    "y = new_data['mean_evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main reason why I agree that negative gearing should be abolished is that it is a major tax break which is largely only available to the wealthy (as unfortunately most tax breaks are). I see no good reason why we should essentially subsidise the property speculations of the wealthy. The consideration that, by driving up housing prices, it makes buying a house that much more unaffordable for first home buyers also seems to be of some importance, as once again this seems to disadvantage those just starting our in life in favour of those with already established wealth.\r\n",
      "I am however somewhat worried that simply abolishing negative gearing would cause significant economic upheaval and drive up rental prices. It seems to me that some sort of gradual 'phasing out' might be best, to give the housing market time to readjust to the new, undistorted, conditions\n"
     ]
    }
   ],
   "source": [
    "print (comments_texts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build vecor with the feature extraction code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'feature_selection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1ddb18cf2366>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfeatures_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# from basic_features import features_summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'feature_selection'"
     ]
    }
   ],
   "source": [
    "from feature_selection import features_summary\n",
    "# from basic_features import features_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = [features_summary(item) for item in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding more features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load data (deserialize)\n",
    "with open('argument_component.pickle', 'rb') as handle:\n",
    "    text_compo_dic = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = new_data['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adding the argument component vectors into the basic feature vector\n",
    "comp_data = [text_compo_dic[item] for item in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_X = np.concatenate((X, comp_data ),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training/test dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print (X_train[0], len(X_train), len(y_train))\n",
    "# print (X_test[0], len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X[0:1716]\n",
    "y_train = y[0:1716]\n",
    "X_test =X[1716:]\n",
    "y_test = y[1716:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adding argument componets data\n",
    "new_X_train = new_X[0:1716]\n",
    "new_y_train = y[0:1716]\n",
    "new_X_test =new_X[1716:]\n",
    "new_y_test = y[1716:]\n",
    "# new_comments = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. regression model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# linear regression model \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(new_X_train, new_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(new_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [  1.66011932e-02  -1.83142927e-02  -7.65621384e-02   3.61766044e-02\n",
      "  -8.48954760e-03   7.38919503e-01  -2.84541353e-02   1.69589207e-01\n",
      "  -7.54648636e-04  -5.74561717e-01   2.58258455e+01   2.64337362e+01\n",
      "   2.64671820e+01   2.88134017e+01   2.79828625e-03   3.61981783e-03\n",
      "   5.75945249e-03   1.67159287e-03   1.72478831e+01   1.72454038e+01\n",
      "   1.64976136e+01   1.65561157e+01]\n",
      "Mean squared error: 2.50\n",
      "Variance score: 0.14\n",
      "mean_absolute_error: 1.29\n"
     ]
    }
   ],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "print(\"mean_absolute_error: %.2f\"\n",
    "      % mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. MLP model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=(10,),  activation='relu', solver='adam', alpha=0.001, batch_size='auto',\n",
    "    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "    random_state=9, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10,), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=1000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=9, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(new_X_train, new_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred1 = mlp.predict(new_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 6.38\n",
      "Variance score: -1.20\n",
      "mean_absolute_error: 1.74\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, pred1))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, pred1))\n",
    "print(\"mean_absolute_error: %.2f\"\n",
    "      % mean_absolute_error(y_test, pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding argument component data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding a pca\n",
    "from sklearn.decomposition import PCA\n",
    "pca_X = pca = PCA(n_components=6)\n",
    "pca.fit(new_X)\n",
    "pca_X = pca.transform(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_X_train = pca_X[0:1716]\n",
    "pca_y_train = y[0:1716]\n",
    "pca_X_test =pca_X[1716:]\n",
    "pca_y_test = y[1716:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp1 = MLPRegressor(\n",
    "    hidden_layer_sizes=(10,),  activation='relu', solver='adam', alpha=0.001, batch_size='auto',\n",
    "    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "    random_state=9, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10,), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=1000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=9, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp1.fit(pca_X_train, pca_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2 = mlp1.predict(pca_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 2.25\n",
      "Variance score: 0.22\n",
      "mean_absolute_error: 1.19\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(pca_y_test, pred2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(pca_y_test, pred2))\n",
    "print(\"mean_absolute_error: %.2f\"\n",
    "      % mean_absolute_error(pca_y_test, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_comment = comments_texts[1716:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846\n"
     ]
    }
   ],
   "source": [
    "# pca_comment = np.array[pca_comment]\n",
    "print (len(pca_comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_y_test = np.array(pca_y_test)\n",
    "pred2 = np.array(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in these days of piracy _ref Somalia - we don't know who is safe and who is armed.  so all arrivals need to go to secure accommodation until we have time and resources to assess them.  There are 5 billion people on the planet, and if 1% want to come here, that is 50 million- much more than we have water for.\n",
      "1.95349238228\n",
      "5.0\n",
      "------\n",
      "If the money goes to feeding the kids breakfast before school, or to one of the parents being able to spend more time with their children to make sure they're supported with their school work at home, I believe a child's education will benefit.\r\n",
      "Relieving financial pressure on low income families can only benefit the child. Creating a safe and positive home environment is just as significant and important in having an impact on a child's education as books and new textbooks.\n",
      "2.87791517361\n",
      "6.0\n",
      "------\n",
      "Maybe there's only so much of the population that will actually make use of a change in the law, but the effects are much greater than that. A gay couple's friends and family are being denied the right to celebrate that relationship too. Also, while there are some tactful arguments against gay marriage, there are many that are basically relying on a view that homosexuality or homosexual behaviours are disgusting and wrong, and that's why they can't get married. A lot air gets taken out of that argument once gay marriage is allowed and the sky doesn't fall in.\n",
      "3.8624289958\n",
      "7.0\n",
      "------\n",
      "Now lets see.  1. The coalition is going to give a tax cut to small and medium business.  2. Big business is not going to get a tax cut.  So 3. overall revenue will be reduced.  4. They are claiming that this will pay for the paid parental leave scheme.  Sorry, how can they claim a reduction in revenue will pay for something?  \n",
      "3.78300107363\n",
      "0.0\n",
      "------\n",
      "When it comes to economic past record the Coalition have it all over the ALP. The ALP wants the Coalition to release figures based on ALP figures that have always been out by $Billions.\n",
      "10.0632804903\n",
      "5.0\n",
      "------\n",
      "If the govt is going to spend the huge amounts on creating an NBN then it makes sense to lay down the proper infrastructure from the beginning.  The liberals plan to scale back the rollout would only mean that in the not too distant future, a great deal more money would need to be spent.  It's a connected world nowadays and Australia needs to be up there Witt the rest of the leading countries. \n",
      "2.73635938116\n",
      "7.0\n",
      "------\n",
      "should you decide to convert from fibre to the node it is goiing to be a very expensive additional cost. It is like painting your house twice within a short space of time\n",
      "3.80823824989\n",
      "7.0\n",
      "------\n",
      "Both arent great... but Abbott is scary and extreme (he is hiding it well). \n",
      "4.39743373814\n",
      "1.0\n",
      "------\n",
      "@ Nathan Lee \r\n",
      "\r\n",
      "Is it your assertion that anyone who might hold a different view to you on this subject must be a racist?\n",
      "2.55368781281\n",
      "6.0\n",
      "------\n",
      "Knowing that every female was born smarter than male babies, we know from our mothers who were able to get us ready for society often with meager funds. Would howl to such an unfair policy as if it is not ridiculous enough to pay one person $ 8.00 an hour and another $ 1500.00 an hour. Because this society has given up a long time ago in an unfair and greedy Christian way. Instead of the New Way Jesus preached.\n",
      "3.41304232571\n",
      "7.0\n",
      "------\n",
      "It's already live in a fair few places. Have a look on the NBN Co's website, there are maps of the roll-out and time frames. \n",
      "9.13405932371\n",
      "4.0\n",
      "------\n",
      "The only thing they can be trusted to do is produce slogans that appeal to the lowest common denominator of the electorate. They only had a surplus because they neglected infrastructure and cut funding to the commonwealth / State housing Agreements. They bribed the middle classes with large 1st home buyer grants and now houses are more unaffordable. \r\n",
      "Abbott said it himself....if its not scripted then you can't take it as fact! \r\n",
      "And if it is scripted then it will be hiding another agenda.\n",
      "4.51863711696\n",
      "1.0\n",
      "------\n",
      "It's about time we implemented effective schooling reforms designed to ensure all young Australians have access to quality education and prospects for higher education, regardless of where they live and regardless of their socio-economic status.\n",
      "1.96775582956\n",
      "5.0\n",
      "------\n",
      "A carbon tax will help to reduce pollution. This is not an opinion. It is a fact. Anyone who feels we are paying for something you cannot see should try spending a couple of years in China. I did and the Jerome Kern song is a reality there. \r\n",
      "\r\n",
      "Is this the world we wish to leave to our kids?\n",
      "1.83213824436\n",
      "5.0\n",
      "------\n",
      "If it is a choice between life and death, refugees will still come to try for a better life for their children. All children should have the right to be free and educated. \n",
      "3.7313184079\n",
      "0.0\n",
      "------\n",
      "This is paid for from the public purse and is not an entitlement. When an employee takes a sick day the employer pays as with holiday pay etc. But this is money raised in taxes and is no different from money raised for New Start or Disability pensions. No point going to Centrelink and explaining to them that you were on $200,000 therefore you are entitled to $75,000.\n",
      "5.28879769987\n",
      "1.0\n",
      "------\n",
      "People in metropolitan capitals can already get 100Mbps Cable from Telstra and Optus, so what Tony Abbott has planned means that in 6 years time he can guarantee a quarter of the speeds that people are currently getting. \r\n",
      "\r\n",
      "I work in IT and although our company has fibre almost all of our interstate offices run on ADSL technology. That means whilst we can video conference with clients overseas who have high speed internet, conferencing with our offices in Australia is patchy at best.\r\n",
      "\r\n",
      "And for all those people who claim that the NBN costs too much and the Liberals have a better plan. If you break down the numbers you see that the Liberal solution will take 75% of the time to build compared to the NBN, cost 58% as much and only deliver 10% of the speeds that the NBN will provide. I don't see how that is a more cost effective solution.\r\n",
      "\r\n",
      "And most people keep forgetting that the NBN should not be seen as an expenditure, but rather as a long term investment as the NBN is scheduled to repay the Government it's investment by 2034. The liberal plan is a stop-gap measure that will eventually need to be upgraded to FTTP at greater cost then currently due to inflation resulting in a greater net cost.\n",
      "9.56416639571\n",
      "4.0\n",
      "------\n",
      "Responsible free speech means we argue the issues, not denigrate the people whose views differ from ours. It means we use words that build, not words emotionally laden with negative meanings that cut and divide.\n",
      "8.55558800829\n",
      "3.66666666667\n",
      "------\n",
      "it is definitely the responsiblity for the government to support household on child care. Especially the higher costs of Australia on early childhood expenditure in family. \n",
      "2.08337413066\n",
      "7.0\n",
      "------\n",
      "Asylum seekers pose no critical problem, threat or issue of any significance to the Australian public. Half the time, the public does not encounter any of those seekers. They are here to seek for a better hope and life. Why would a developed country deny such access?\n",
      "3.55432922592\n",
      "0.0\n",
      "------\n",
      "A 'free' media is crucial to a democratic process anything like worthy of the name. In reality a free media is made more likely when those that control the media are many and varied. One very significant contributor to the variety is public broadcasting. It is not a guarantee, because powerful people can get hold of it, and use it to their undemocratic advantage, in which case we need an independent private media to balance the hijacked public voice. And vice versa. Public broadcasting can not be run by the private sector, certainly not in this very important sense.\r\n",
      "As far as I'm concerned privatising the ABC would be a heinous crime against Australia, and the vast majority of Australians whether they realise it or not; and anyone responsible for such a crime against our democracy would deserve many years in prison, or worse.\n",
      "4.27399846911\n",
      "1.0\n",
      "------\n",
      "The media today should be more regulated by the government to be more objective, backed up and critical. Today, the majority of the media carry subjective messages to a large audience. The majority of the same audience may believe what they read in the news is fact, regardless of what may be the case.\n",
      "3.38896808375\n",
      "0.0\n",
      "------\n",
      "Maintenance of these subsidies is a global scandal, a crime against the environment and an active instrument against clean energy and technological innovation. I strongly support transforming fossil fuel subsidies into an effective scheme for financing energy efficiency and renewables and making sure that the poor in developing countries benefit appropriately and receive clean, affordable and reliable energy\n",
      "4.04528912015\n",
      "1.0\n",
      "------\n",
      "It will not be a financial pressure for the companies, since the topic said all new mothers be supported by the government for up to six months at their current wage or salary\n",
      "9.07202093476\n",
      "6.0\n",
      "------\n",
      " There is no any clearly boundaries to setttel what kind of questions should be tested.\n",
      "6.05840372956\n",
      "1.0\n",
      "------\n",
      "academic tests can provide a standard to make sure that who is a qualified teacher\n",
      "7.96389445697\n",
      "1.0\n",
      "------\n",
      "it is never easy for poor family to support education even in developed countires like Australia. It might hard for government to control the actual usage of the this Bouns, however better superasion can be maintained rather than wiping it away. For instance, this Bouns could direclty transfer from government assigned account to school account they are children registered directly. This will make sure all the funding that the house needed has been putted to children's education.\n",
      "3.46651200933\n",
      "0.0\n",
      "------\n",
      "I support same-sex marriage. Marriage is about love, if two people love each other and they can not get married only because they have same sex, it is unfair. Everybody have the right to get married. Same sex marriage can benefit the society, they can adopt kids for creche if they want to have kids. \n",
      "4.17337817879\n",
      "0.0\n",
      "------\n",
      "The online versions of few English dictionaries acknowledge that marriage is no longer limited to a man and a woman. And the next paper edition published will do the same. Same-sex marriage is real marriage\n",
      "4.33178458325\n",
      "0.0\n",
      "------\n",
      "it is so curel for children to stay in the detention centres. \n",
      "3.59620895169\n",
      "7.0\n",
      "------\n",
      "Rights for returning back to work enviornment not only benefit the family as a whole but also for monthers themselvers. supporting from government to offer quality childcare would benefit the family so much\n",
      "3.80402090935\n",
      "7.0\n",
      "------\n",
      "Why should straight people be allowed to get married but not gay, gay people are the same as everyone else. Gay people should be able to get married because its unfair to them to not even get the choice to get married.\r\n",
      "The only difference between homosexual couples and heterosexual couples is whom they choose to love. That's it. Yet, for some reason, we feel that it is okay to deny them the same rights heterosexuals receive, but for what reason?  I believe that they have the right to be happy and be treated as equals. \r\n",
      "Love is love.\n",
      "2.95038701689\n",
      "6.0\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "tmp = 0 \n",
    "for i in range(len(pred2)):\n",
    "    try:\n",
    "        if abs(pred2[i] - pca_y_test[i]) > 3:\n",
    "            print (comments_texts[i+1716])\n",
    "            print (pred2[i])\n",
    "            print (pca_y_test[i])\n",
    "            tmp += 1\n",
    "            print (\"------\")\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "print (tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding tf-idf information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the tf-idf information is because, I observed that some comments only have one sentence after removing the links in that. If this sentence is quite similiar with the title, the score would be 0, otherwise, it is 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load data (deserialize)\n",
    "with open('url_sim_dic.pickle', 'rb') as handle:\n",
    "    url_sim_dic = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_tfidf = [url_sim_dic[item] for item in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_with_tfidf = np.concatenate((new_X, url_tfidf),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca2 = PCA(n_components=4)\n",
    "pca2.fit(data_with_tfidf)\n",
    "data_with_tfidf = pca2.transform(data_with_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2562, 4)\n",
      "(2562, 22)\n"
     ]
    }
   ],
   "source": [
    "print (data_with_tfidf.shape)\n",
    "print (new_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding argument componets data\n",
    "X_train_tfidf = data_with_tfidf[0:1716]\n",
    "y_train_tfidf = y[0:1716]\n",
    "X_test_tfidf =data_with_tfidf[1716:]\n",
    "y_test_tfidf = y[1716:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp2 = MLPRegressor(\n",
    "    hidden_layer_sizes=(10,),  activation='relu', solver='adam', alpha=0.001, batch_size='auto',\n",
    "    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "    random_state=9, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10,), learning_rate='constant',\n",
       "       learning_rate_init=0.01, max_iter=1000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=9, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.fit(X_train_tfidf, y_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred3 = mlp2.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 2.15\n",
      "Variance score: 0.26\n",
      "mean_absolute_error: 1.20\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test_tfidf, pred3))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test_tfidf, pred3))\n",
    "print(\"mean_absolute_error: %.2f\"\n",
    "      % mean_absolute_error(y_test_tfidf, pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846 846 846\n"
     ]
    }
   ],
   "source": [
    "test_data = comments_texts[1716:]\n",
    "print (len(X_test), len(y_pred), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.array(pca_y_test)\n",
    "y_test = np.array(y_test)\n",
    "test_data = np.array(test_data)\n",
    "print (y_pred[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(X_test)):\n",
    "    if y_pred[i] - y_test[i] > 1:\n",
    "        print (test_data[i+1716])\n",
    "        print (y_pred[i])\n",
    "        print (y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 27.0, 3.0, 9.0, 2]\n"
     ]
    }
   ],
   "source": [
    "print (X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
