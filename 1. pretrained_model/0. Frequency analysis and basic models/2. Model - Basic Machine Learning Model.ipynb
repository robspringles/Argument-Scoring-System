{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('argument_words.pickle', 'rb') as handle:\n",
    "    common_words = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding the most_common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freq_words(number, words):\n",
    "    '''\n",
    "    return the words which the frequency is higher than the given number\n",
    "    number: the lowest value of frequency\n",
    "    words: the cleared words list\n",
    "    '''\n",
    "    word_freq = FreqDist(words).most_common(1000)\n",
    "    words_list = [key for (key, value) in word_freq if value > number]\n",
    "    return words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_words = common_words['all']\n",
    "# word_list = freq_words(28, input_words)\n",
    "word_list = freq_words(10, input_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input the labeled sents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('argument_words.pickle', 'rb') as handle:\n",
    "    common_words = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('labeled_essay_dics.pickle', 'rb') as handle:\n",
    "    label_sents = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute and store and the {sents: label} into one dic\n",
    "all_label_sents = {}\n",
    "for key in label_sents.keys():\n",
    "    this_essay = label_sents[key]\n",
    "    for s in this_essay.keys():\n",
    "        all_label_sents[s] = this_essay[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sents cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Original taken from https://github.com/dennybritz/cnn-text-classification-tf\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_split_str(s):\n",
    "    strip_s = s.strip()\n",
    "    clear_s = clean_str(strip_s)\n",
    "    s_text = clear_s.split(\" \")\n",
    "    return s_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buiding bag-of-words vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_BOW(text):\n",
    "    BOW = {}\n",
    "    for word in text:\n",
    "        BOW[word] = BOW.get(word,0) + 1\n",
    "    return BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for key in all_label_sents.keys():\n",
    "    new_key = []\n",
    "    for w in clear_split_str(key):\n",
    "        if w in word_list:\n",
    "            new_key.append(w)\n",
    "    X.append(get_BOW(new_key))\n",
    "    y.append(all_label_sents[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Premise', 'Empty', 'Premise', 'Premise', 'Empty', 'Premise', 'Empty', 'Empty', 'MajorClaim']\n"
     ]
    }
   ],
   "source": [
    "print (y[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## vectorize the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_vector = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = \"i am ok\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_vector, \n",
    "                                                   y,\n",
    "                                                   test_size = 0.2\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5661, 1000)\n",
      "(1416, 1000)\n",
      "5661\n",
      "1416\n"
     ]
    }
   ],
   "source": [
    "print ((X_train.shape))\n",
    "print ((X_test.shape))\n",
    "print (len(y_train))\n",
    "print (len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Premise', 683), ('Empty', 316), ('Claim', 273), ('MajorClaim', 144)]\n"
     ]
    }
   ],
   "source": [
    "print (FreqDist(y_test).most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.507768361581921\n"
     ]
    }
   ],
   "source": [
    "print (float(719/(719+302+276+119)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the (alpha, accuracy) pairs in MultinomialNB:\n",
      "0.1 0.60593220339\n",
      "0.2 0.608050847458\n",
      "0.30000000000000004 0.608757062147\n",
      "0.4 0.608757062147\n",
      "0.5 0.608757062147\n",
      "0.6000000000000001 0.605225988701\n",
      "0.7000000000000001 0.608050847458\n",
      "0.8 0.611581920904\n",
      "0.9 0.612994350282\n",
      "1.0 0.612994350282\n",
      "1.1 0.61511299435\n",
      "1.2000000000000002 0.613700564972\n",
      "1.3 0.612994350282\n",
      "1.4000000000000001 0.612288135593\n",
      "1.5 0.610875706215\n",
      "1.6 0.611581920904\n",
      "1.7000000000000002 0.612288135593\n",
      "1.8 0.610875706215\n",
      "1.9000000000000001 0.608757062147\n",
      "2.0 0.608757062147\n",
      "2.1 0.610875706215\n",
      "2.2 0.610875706215\n",
      "2.3000000000000003 0.612288135593\n",
      "2.4000000000000004 0.612994350282\n",
      "2.5 0.613700564972\n",
      "2.6 0.613700564972\n",
      "2.7 0.61581920904\n",
      "2.8000000000000003 0.614406779661\n",
      "2.9000000000000004 0.611581920904\n"
     ]
    }
   ],
   "source": [
    "print (\"the (alpha, accuracy) pairs in MultinomialNB:\")\n",
    "i = 0.1 \n",
    "best_accuracy = 0.0\n",
    "best_alpha = 0.0\n",
    "\n",
    "for alpha_value in range(1,30):\n",
    "    clf = MultinomialNB(alpha=alpha_value*0.1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    prediciton = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,prediciton)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_alpha = alpha_value*0.1\n",
    "    print (alpha_value*0.1, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Premise', 836), ('Empty', 243), ('Claim', 192), ('MajorClaim', 145)]\n"
     ]
    }
   ],
   "source": [
    "print (FreqDist(prediciton).most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the (alpha, accuracy) pairs in LogisticRegression:\n",
      "0.1 0.635593220339\n",
      "0.2 0.636299435028\n",
      "0.30000000000000004 0.641242937853\n",
      "0.4 0.637711864407\n",
      "0.5 0.641949152542\n",
      "0.6000000000000001 0.639830508475\n",
      "0.7000000000000001 0.637005649718\n",
      "0.8 0.638418079096\n",
      "0.9 0.633474576271\n",
      "1.0 0.63418079096\n",
      "1.1 0.63488700565\n",
      "1.2000000000000002 0.63418079096\n",
      "1.3 0.635593220339\n",
      "1.4000000000000001 0.635593220339\n",
      "1.5 0.636299435028\n",
      "1.6 0.63488700565\n",
      "1.7000000000000002 0.63418079096\n",
      "1.8 0.632062146893\n",
      "1.9000000000000001 0.632768361582\n",
      "2.0 0.629943502825\n",
      "2.1 0.628531073446\n",
      "2.2 0.627824858757\n",
      "2.3000000000000003 0.626412429379\n",
      "2.4000000000000004 0.626412429379\n",
      "2.5 0.625\n",
      "2.6 0.624293785311\n",
      "2.7 0.623587570621\n",
      "2.8000000000000003 0.622175141243\n",
      "2.9000000000000004 0.621468926554\n"
     ]
    }
   ],
   "source": [
    "print (\"the (alpha, accuracy) pairs in LogisticRegression:\")\n",
    "best_accuracy = 0.0\n",
    "best_C = 0.0\n",
    "for C_value in range(1,30):\n",
    "    clf1 = LogisticRegression(C=C_value*0.1)\n",
    "    clf1.fit(X_train, y_train)\n",
    "    prediciton2 = clf1.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,prediciton2)\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_C = C_value*0.1\n",
    "    print (C_value*0.1, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Premise', 780), ('Empty', 290), ('Claim', 220), ('MajorClaim', 126)]\n"
     ]
    }
   ],
   "source": [
    "print (FreqDist(prediciton2).most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('logisticRegression_model.pickle', 'wb') as handle:\n",
    "#     pickle.dump([clf1, X_test, y_test], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf = svm.SVC(verbose=True)\n",
    "clf3 = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediciton3 = clf3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60593220339\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,prediciton3)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Premise', 755), ('Empty', 299), ('Claim', 221), ('MajorClaim', 141)]\n"
     ]
    }
   ],
   "source": [
    "print (FreqDist(prediciton3).most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "comment_path = 'comment_sent.csv'\n",
    "label_comments_data = pd.read_csv(comment_path,encoding = \"ISO-8859-1\")\n",
    "label_sents = label_comments_data['sentence']\n",
    "label_components = label_comments_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print (label_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sents_vector = [clear_split_str(item) for item in label_sents]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_X = []\n",
    "for key in sents_vector:\n",
    "    new_key = []\n",
    "    for w in key:\n",
    "        if w in word_list:\n",
    "            new_key.append(w)\n",
    "    new_X.append(get_BOW(new_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print (new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_X_vector_label = vectorizer.fit_transform(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(new_X_vector_label, \n",
    "                                                   label_components,\n",
    "                                                   test_size = 0.2\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(new_X_train, new_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 345) (20, 345)\n"
     ]
    }
   ],
   "source": [
    "print (new_X_train.shape, new_X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test,prediciton3)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
